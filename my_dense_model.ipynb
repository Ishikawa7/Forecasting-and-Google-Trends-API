{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Ospiti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-03</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-05</td>\n",
       "      <td>571.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>247.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Data  Ospiti\n",
       "0    2021-06-01   319.0\n",
       "1    2021-06-02   396.0\n",
       "2    2021-06-03   188.0\n",
       "3    2021-06-04   258.0\n",
       "4    2021-06-05   571.0\n",
       "..          ...     ...\n",
       "542  2022-11-26   732.0\n",
       "543  2022-11-27   495.0\n",
       "544  2022-11-28   226.0\n",
       "545  2022-11-29   289.0\n",
       "546  2022-11-30   247.0\n",
       "\n",
       "[547 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "y = pd.read_csv(\"input/Ospiti.csv\")\n",
    "y[\"Data\"] = pd.to_datetime(y[\"Data\"]).dt.date\n",
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2022-12-01', '2022-12-02', '2022-12-03', '2022-12-04',\n",
       "               '2022-12-05', '2022-12-06', '2022-12-07'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.date_range(start=y[\"Data\"].iloc[-1],periods=8)[1:]\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 319.        ,  396.        ,  188.        ,  258.        ,\n",
       "        571.        ,  488.        ,  214.        ,  259.        ,\n",
       "        373.        ,  344.        ,  333.        ,  473.        ,\n",
       "        352.        ,  220.        ,  338.        ,  197.        ,\n",
       "        271.        ,  350.        ,  500.        ,  345.        ,\n",
       "        217.        ,  271.        ,  334.        ,  336.        ,\n",
       "        352.        ,  275.        ,  325.        ,  283.        ,\n",
       "        317.        ,  292.        ,  285.        ,  218.        ,\n",
       "        490.        ,  429.        ,  302.        ,  201.        ,\n",
       "        349.        ,  400.        ,  355.        ,  469.        ,\n",
       "        185.        ,  212.        ,  301.        ,  298.        ,\n",
       "        348.        ,  316.        ,  582.        ,  306.        ,\n",
       "        327.        ,  293.        ,  335.        ,  332.        ,\n",
       "        308.        ,  469.        ,  435.        ,  282.        ,\n",
       "        303.        ,  346.        ,  310.        ,  360.        ,\n",
       "        534.        ,  382.        ,  355.        ,  317.        ,\n",
       "        422.        ,  414.        ,  293.        ,  357.        ,\n",
       "        272.        ,  249.        ,  267.        ,  245.        ,\n",
       "        387.        ,  294.        ,  325.        ,  260.        ,\n",
       "        339.        ,  384.        ,  378.        ,  374.        ,\n",
       "        420.        ,  526.        ,  385.        ,  174.        ,\n",
       "        259.        ,  290.        ,  292.        ,  304.        ,\n",
       "        512.        ,  388.        ,  250.        ,  209.        ,\n",
       "        287.        ,  304.        ,  358.        ,  584.        ,\n",
       "        455.        ,  293.        ,  258.        ,  332.        ,\n",
       "        356.        ,  377.        ,  611.68383163,  352.        ,\n",
       "        288.        ,  250.        ,  303.        ,  340.        ,\n",
       "        401.        ,  740.        ,  468.        ,  244.        ,\n",
       "        313.        ,  353.        ,  326.        ,  375.        ,\n",
       "        686.        ,  370.        ,  239.        ,  289.        ,\n",
       "        297.        ,  376.        ,  440.        ,  745.        ,\n",
       "        409.        ,  211.        ,  271.        ,  298.        ,\n",
       "        312.        ,  391.        ,  802.        ,  533.        ,\n",
       "        224.        ,  313.        ,  311.        ,  302.        ,\n",
       "        497.        ,  663.        ,  503.        ,  278.        ,\n",
       "        270.        ,  314.        ,  356.        ,  361.        ,\n",
       "        714.        ,  468.        ,  242.        ,  274.        ,\n",
       "        278.        ,  340.        ,  423.        ,  689.        ,\n",
       "        603.        ,  497.        ,  254.        ,  314.        ,\n",
       "        296.        ,  410.        ,  717.        ,  407.        ,\n",
       "        262.        ,  286.        ,  237.        ,  284.        ,\n",
       "        408.        ,  865.        ,  383.        ,  260.        ,\n",
       "        344.        ,  255.        ,  317.        ,  426.        ,\n",
       "        646.        ,  458.        ,  268.        ,  276.        ,\n",
       "        316.        ,  293.        ,  390.        ,  685.        ,\n",
       "        397.        ,  261.        ,  324.        ,  277.        ,\n",
       "        312.        ,  469.        ,  648.        ,  392.        ,\n",
       "        231.        ,  343.        ,  225.        ,  261.        ,\n",
       "        442.        ,  575.        ,  326.        ,  264.        ,\n",
       "        401.        ,  364.        ,  381.        ,  533.        ,\n",
       "        618.        ,  487.        ,  368.        ,  392.        ,\n",
       "        418.        ,  392.        ,  244.        ,  186.        ,\n",
       "        191.        ,  252.        ,  212.        ,  208.        ,\n",
       "        286.        ,  228.        ,  349.        ,  199.        ,\n",
       "        234.        ,  266.        ,  253.        ,  221.        ,\n",
       "        335.        ,  217.        ,  125.        ,  117.        ,\n",
       "        387.        ,  156.        ,  199.        ,  391.        ,\n",
       "        248.        ,  165.        ,  207.        ,  232.        ,\n",
       "        238.        ,  242.        ,  499.        ,  288.        ,\n",
       "        161.        ,  213.        ,  236.        ,  216.        ,\n",
       "        344.        ,  562.        ,  326.        ,  168.        ,\n",
       "        248.        ,  299.        ,  225.        ,  355.        ,\n",
       "        591.        ,  363.        ,  194.        ,  211.        ,\n",
       "        217.        ,  268.        ,  339.        , 1183.        ,\n",
       "        484.        ,  355.        ,  290.        ,  244.        ,\n",
       "        292.        ,  426.        ,  754.        ,  511.        ,\n",
       "        217.        ,  313.        ,  304.        ,  252.        ,\n",
       "        421.        ,  820.        ,  454.        ,  231.        ,\n",
       "        295.        ,  339.        ,  325.        ,  390.        ,\n",
       "        699.        ,  482.        ,  221.        ,  315.        ,\n",
       "        331.        ,  332.        ,  316.        ,  635.        ,\n",
       "        489.        ,  196.        ,  296.        ,  276.        ,\n",
       "        320.        ,  424.        ,  860.        ,  575.        ,\n",
       "        250.        ,  278.        ,  283.        ,  298.        ,\n",
       "        394.        ,  658.        ,  429.        ,  244.        ,\n",
       "        218.        ,  299.        ,  251.        ,  377.        ,\n",
       "        869.        ,  493.        ,  261.        ,  329.        ,\n",
       "        310.        ,  320.        ,  421.        ,  746.        ,\n",
       "        440.        ,  293.        ,  349.        ,  280.        ,\n",
       "        369.        ,  362.        ,  387.        ,  509.        ,\n",
       "        382.        ,  194.        ,  266.        ,  298.        ,\n",
       "        385.        ,  585.        ,  544.        ,  484.        ,\n",
       "        246.        ,  304.        ,  298.        ,  339.        ,\n",
       "        775.        ,  530.        ,  222.        ,  265.        ,\n",
       "        287.        ,  340.        ,  413.        ,  844.        ,\n",
       "        979.        ,  312.        ,  273.        ,  274.        ,\n",
       "        377.        ,  379.        ,  684.        ,  558.        ,\n",
       "        270.        ,  329.        ,  310.        ,  313.        ,\n",
       "        397.        ,  673.        ,  437.        ,  285.        ,\n",
       "        276.        ,  291.        ,  385.        ,  485.        ,\n",
       "        646.        ,  579.        ,  255.        ,  329.        ,\n",
       "        339.        ,  557.        ,  357.        ,  525.        ,\n",
       "        459.        ,  282.        ,  358.        ,  435.        ,\n",
       "        317.        ,  430.        ,  522.        ,  363.        ,\n",
       "        255.        ,  367.        ,  349.        ,  344.        ,\n",
       "        433.        ,  605.        ,  393.        ,  258.        ,\n",
       "        346.        ,  400.        ,  336.        ,  472.        ,\n",
       "        533.        ,  371.        ,  279.        ,  369.        ,\n",
       "        360.        ,  368.        ,  371.        ,  585.        ,\n",
       "        400.        ,  263.        ,  301.        ,  365.        ,\n",
       "        377.        ,  362.        ,  545.        ,  390.        ,\n",
       "        301.        ,  338.        ,  349.        ,  308.        ,\n",
       "        404.        ,  488.        ,  422.        ,  278.        ,\n",
       "        324.        ,  369.        ,  343.        ,  315.        ,\n",
       "        591.        ,  418.        ,  351.        ,  372.        ,\n",
       "        380.        ,  387.        ,  382.46212306,  556.        ,\n",
       "        392.        ,  327.        ,  357.        ,  351.        ,\n",
       "        425.        ,  436.        ,  587.        ,  522.        ,\n",
       "        357.        ,  311.        ,  397.        ,  350.        ,\n",
       "        452.        ,  450.        ,  417.        ,  790.        ,\n",
       "        427.        ,  391.        ,  508.        ,  566.        ,\n",
       "        635.        ,  529.        ,  357.        ,  385.        ,\n",
       "        366.        ,  417.        ,  347.        ,  635.        ,\n",
       "        556.        ,  282.        ,  259.        ,  351.        ,\n",
       "        335.        ,  477.        ,  680.        ,  437.        ,\n",
       "        332.        ,  298.        ,  360.        ,  380.        ,\n",
       "        489.        ,  629.        ,  499.        ,  307.        ,\n",
       "        351.        ,  314.        ,  275.        ,  477.        ,\n",
       "        778.        ,  402.        ,  272.        ,  353.        ,\n",
       "        357.        ,  277.        ,  438.        ,  771.        ,\n",
       "        500.        ,  237.        ,  266.        ,  388.        ,\n",
       "        290.        ,  369.        ,  793.        ,  571.        ,\n",
       "        281.        ,  247.        ,  339.        ,  330.        ,\n",
       "        399.        ,  715.        ,  574.        ,  287.        ,\n",
       "        257.        ,  255.        ,  288.        ,  404.        ,\n",
       "        845.        ,  482.        ,  220.        ,  306.        ,\n",
       "        336.        ,  361.        ,  400.        ,  913.        ,\n",
       "        582.        ,  259.        ,  307.        ,  308.        ,\n",
       "        425.        ,  428.        ,  620.        ,  631.        ,\n",
       "        580.        ,  489.        ,  221.        ,  285.        ,\n",
       "        371.        ,  701.        ,  435.        ,  206.        ,\n",
       "        294.        ,  349.        ,  304.        ,  419.        ,\n",
       "        814.        ,  431.        ,  194.        ,  284.        ,\n",
       "        322.        ,  306.        ,  469.        ,  697.        ,\n",
       "        542.        ,  249.        ,  324.        ,  315.        ,\n",
       "        315.        ,  375.        ,  732.        ,  495.        ,\n",
       "        226.        ,  289.        ,  247.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[\"Ospiti\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18949343],\n",
       "       [0.26172608],\n",
       "       [0.06660413],\n",
       "       [0.13227017],\n",
       "       [0.42589118],\n",
       "       [0.34803002],\n",
       "       [0.09099437],\n",
       "       [0.13320826],\n",
       "       [0.24015009],\n",
       "       [0.21294559],\n",
       "       [0.20262664],\n",
       "       [0.33395872],\n",
       "       [0.22045028],\n",
       "       [0.09662289],\n",
       "       [0.20731707],\n",
       "       [0.0750469 ],\n",
       "       [0.14446529],\n",
       "       [0.21857411],\n",
       "       [0.35928705],\n",
       "       [0.21388368],\n",
       "       [0.09380863],\n",
       "       [0.14446529],\n",
       "       [0.20356473],\n",
       "       [0.2054409 ],\n",
       "       [0.22045028],\n",
       "       [0.14821764],\n",
       "       [0.19512195],\n",
       "       [0.15572233],\n",
       "       [0.18761726],\n",
       "       [0.1641651 ],\n",
       "       [0.1575985 ],\n",
       "       [0.09474672],\n",
       "       [0.34990619],\n",
       "       [0.29268293],\n",
       "       [0.17354597],\n",
       "       [0.07879925],\n",
       "       [0.21763602],\n",
       "       [0.26547842],\n",
       "       [0.22326454],\n",
       "       [0.33020638],\n",
       "       [0.06378987],\n",
       "       [0.0891182 ],\n",
       "       [0.17260788],\n",
       "       [0.16979362],\n",
       "       [0.21669794],\n",
       "       [0.18667917],\n",
       "       [0.43621013],\n",
       "       [0.17729831],\n",
       "       [0.19699812],\n",
       "       [0.16510319],\n",
       "       [0.20450281],\n",
       "       [0.20168856],\n",
       "       [0.17917448],\n",
       "       [0.33020638],\n",
       "       [0.29831144],\n",
       "       [0.15478424],\n",
       "       [0.17448405],\n",
       "       [0.21482176],\n",
       "       [0.18105066],\n",
       "       [0.22795497],\n",
       "       [0.39118199],\n",
       "       [0.24859287],\n",
       "       [0.22326454],\n",
       "       [0.18761726],\n",
       "       [0.28611632],\n",
       "       [0.27861163],\n",
       "       [0.16510319],\n",
       "       [0.22514071],\n",
       "       [0.14540338],\n",
       "       [0.12382739],\n",
       "       [0.14071295],\n",
       "       [0.12007505],\n",
       "       [0.2532833 ],\n",
       "       [0.16604128],\n",
       "       [0.19512195],\n",
       "       [0.13414634],\n",
       "       [0.20825516],\n",
       "       [0.25046904],\n",
       "       [0.24484053],\n",
       "       [0.24108818],\n",
       "       [0.28424015],\n",
       "       [0.3836773 ],\n",
       "       [0.25140713],\n",
       "       [0.05347092],\n",
       "       [0.13320826],\n",
       "       [0.16228893],\n",
       "       [0.1641651 ],\n",
       "       [0.17542214],\n",
       "       [0.37054409],\n",
       "       [0.25422139],\n",
       "       [0.12476548],\n",
       "       [0.08630394],\n",
       "       [0.15947467],\n",
       "       [0.17542214],\n",
       "       [0.2260788 ],\n",
       "       [0.4380863 ],\n",
       "       [0.31707317],\n",
       "       [0.16510319],\n",
       "       [0.13227017],\n",
       "       [0.20168856],\n",
       "       [0.22420263],\n",
       "       [0.24390244],\n",
       "       [0.46405613],\n",
       "       [0.22045028],\n",
       "       [0.16041276],\n",
       "       [0.12476548],\n",
       "       [0.17448405],\n",
       "       [0.20919325],\n",
       "       [0.26641651],\n",
       "       [0.58442777],\n",
       "       [0.32926829],\n",
       "       [0.11913696],\n",
       "       [0.18386492],\n",
       "       [0.22138837],\n",
       "       [0.19606004],\n",
       "       [0.24202627],\n",
       "       [0.53377111],\n",
       "       [0.23733583],\n",
       "       [0.11444653],\n",
       "       [0.16135084],\n",
       "       [0.16885553],\n",
       "       [0.24296435],\n",
       "       [0.30300188],\n",
       "       [0.5891182 ],\n",
       "       [0.2739212 ],\n",
       "       [0.08818011],\n",
       "       [0.14446529],\n",
       "       [0.16979362],\n",
       "       [0.18292683],\n",
       "       [0.25703565],\n",
       "       [0.64258912],\n",
       "       [0.3902439 ],\n",
       "       [0.10037523],\n",
       "       [0.18386492],\n",
       "       [0.18198874],\n",
       "       [0.17354597],\n",
       "       [0.3564728 ],\n",
       "       [0.51219512],\n",
       "       [0.36210131],\n",
       "       [0.15103189],\n",
       "       [0.1435272 ],\n",
       "       [0.184803  ],\n",
       "       [0.22420263],\n",
       "       [0.22889306],\n",
       "       [0.56003752],\n",
       "       [0.32926829],\n",
       "       [0.11726079],\n",
       "       [0.14727955],\n",
       "       [0.15103189],\n",
       "       [0.20919325],\n",
       "       [0.28705441],\n",
       "       [0.53658537],\n",
       "       [0.45590994],\n",
       "       [0.3564728 ],\n",
       "       [0.12851782],\n",
       "       [0.184803  ],\n",
       "       [0.16791745],\n",
       "       [0.27485929],\n",
       "       [0.56285178],\n",
       "       [0.27204503],\n",
       "       [0.13602251],\n",
       "       [0.15853659],\n",
       "       [0.11257036],\n",
       "       [0.15666041],\n",
       "       [0.27298311],\n",
       "       [0.70168856],\n",
       "       [0.24953096],\n",
       "       [0.13414634],\n",
       "       [0.21294559],\n",
       "       [0.12945591],\n",
       "       [0.18761726],\n",
       "       [0.28986867],\n",
       "       [0.49624765],\n",
       "       [0.31988743],\n",
       "       [0.14165103],\n",
       "       [0.14915572],\n",
       "       [0.18667917],\n",
       "       [0.16510319],\n",
       "       [0.25609756],\n",
       "       [0.53283302],\n",
       "       [0.26266417],\n",
       "       [0.13508443],\n",
       "       [0.19418386],\n",
       "       [0.15009381],\n",
       "       [0.18292683],\n",
       "       [0.33020638],\n",
       "       [0.49812383],\n",
       "       [0.25797373],\n",
       "       [0.10694184],\n",
       "       [0.2120075 ],\n",
       "       [0.10131332],\n",
       "       [0.13508443],\n",
       "       [0.30487805],\n",
       "       [0.42964353],\n",
       "       [0.19606004],\n",
       "       [0.13789869],\n",
       "       [0.26641651],\n",
       "       [0.23170732],\n",
       "       [0.24765478],\n",
       "       [0.3902439 ],\n",
       "       [0.46998124],\n",
       "       [0.34709193],\n",
       "       [0.23545966],\n",
       "       [0.25797373],\n",
       "       [0.28236398],\n",
       "       [0.25797373],\n",
       "       [0.11913696],\n",
       "       [0.06472795],\n",
       "       [0.06941839],\n",
       "       [0.12664165],\n",
       "       [0.0891182 ],\n",
       "       [0.08536585],\n",
       "       [0.15853659],\n",
       "       [0.10412758],\n",
       "       [0.21763602],\n",
       "       [0.07692308],\n",
       "       [0.1097561 ],\n",
       "       [0.13977486],\n",
       "       [0.12757974],\n",
       "       [0.09756098],\n",
       "       [0.20450281],\n",
       "       [0.09380863],\n",
       "       [0.00750469],\n",
       "       [0.        ],\n",
       "       [0.2532833 ],\n",
       "       [0.03658537],\n",
       "       [0.07692308],\n",
       "       [0.25703565],\n",
       "       [0.12288931],\n",
       "       [0.04502814],\n",
       "       [0.08442777],\n",
       "       [0.10787992],\n",
       "       [0.11350844],\n",
       "       [0.11726079],\n",
       "       [0.35834897],\n",
       "       [0.16041276],\n",
       "       [0.0412758 ],\n",
       "       [0.09005629],\n",
       "       [0.11163227],\n",
       "       [0.09287054],\n",
       "       [0.21294559],\n",
       "       [0.41744841],\n",
       "       [0.19606004],\n",
       "       [0.0478424 ],\n",
       "       [0.12288931],\n",
       "       [0.17073171],\n",
       "       [0.10131332],\n",
       "       [0.22326454],\n",
       "       [0.44465291],\n",
       "       [0.23076923],\n",
       "       [0.07223265],\n",
       "       [0.08818011],\n",
       "       [0.09380863],\n",
       "       [0.14165103],\n",
       "       [0.20825516],\n",
       "       [1.        ],\n",
       "       [0.34427767],\n",
       "       [0.22326454],\n",
       "       [0.16228893],\n",
       "       [0.11913696],\n",
       "       [0.1641651 ],\n",
       "       [0.28986867],\n",
       "       [0.59756098],\n",
       "       [0.369606  ],\n",
       "       [0.09380863],\n",
       "       [0.18386492],\n",
       "       [0.17542214],\n",
       "       [0.12664165],\n",
       "       [0.28517824],\n",
       "       [0.65947467],\n",
       "       [0.31613508],\n",
       "       [0.10694184],\n",
       "       [0.16697936],\n",
       "       [0.20825516],\n",
       "       [0.19512195],\n",
       "       [0.25609756],\n",
       "       [0.54596623],\n",
       "       [0.3424015 ],\n",
       "       [0.09756098],\n",
       "       [0.18574109],\n",
       "       [0.20075047],\n",
       "       [0.20168856],\n",
       "       [0.18667917],\n",
       "       [0.48592871],\n",
       "       [0.34896811],\n",
       "       [0.07410882],\n",
       "       [0.16791745],\n",
       "       [0.14915572],\n",
       "       [0.19043152],\n",
       "       [0.2879925 ],\n",
       "       [0.69699812],\n",
       "       [0.42964353],\n",
       "       [0.12476548],\n",
       "       [0.15103189],\n",
       "       [0.15572233],\n",
       "       [0.16979362],\n",
       "       [0.25984991],\n",
       "       [0.50750469],\n",
       "       [0.29268293],\n",
       "       [0.11913696],\n",
       "       [0.09474672],\n",
       "       [0.17073171],\n",
       "       [0.12570356],\n",
       "       [0.24390244],\n",
       "       [0.7054409 ],\n",
       "       [0.35272045],\n",
       "       [0.13508443],\n",
       "       [0.1988743 ],\n",
       "       [0.18105066],\n",
       "       [0.19043152],\n",
       "       [0.28517824],\n",
       "       [0.59005629],\n",
       "       [0.30300188],\n",
       "       [0.16510319],\n",
       "       [0.21763602],\n",
       "       [0.15290807],\n",
       "       [0.23639775],\n",
       "       [0.22983114],\n",
       "       [0.2532833 ],\n",
       "       [0.36772983],\n",
       "       [0.24859287],\n",
       "       [0.07223265],\n",
       "       [0.13977486],\n",
       "       [0.16979362],\n",
       "       [0.25140713],\n",
       "       [0.43902439],\n",
       "       [0.40056285],\n",
       "       [0.34427767],\n",
       "       [0.12101313],\n",
       "       [0.17542214],\n",
       "       [0.16979362],\n",
       "       [0.20825516],\n",
       "       [0.61726079],\n",
       "       [0.38742964],\n",
       "       [0.09849906],\n",
       "       [0.13883677],\n",
       "       [0.15947467],\n",
       "       [0.20919325],\n",
       "       [0.27767355],\n",
       "       [0.68198874],\n",
       "       [0.80863039],\n",
       "       [0.18292683],\n",
       "       [0.14634146],\n",
       "       [0.14727955],\n",
       "       [0.24390244],\n",
       "       [0.24577861],\n",
       "       [0.53189493],\n",
       "       [0.41369606],\n",
       "       [0.1435272 ],\n",
       "       [0.1988743 ],\n",
       "       [0.18105066],\n",
       "       [0.18386492],\n",
       "       [0.26266417],\n",
       "       [0.52157598],\n",
       "       [0.30018762],\n",
       "       [0.1575985 ],\n",
       "       [0.14915572],\n",
       "       [0.16322702],\n",
       "       [0.25140713],\n",
       "       [0.34521576],\n",
       "       [0.49624765],\n",
       "       [0.43339587],\n",
       "       [0.12945591],\n",
       "       [0.1988743 ],\n",
       "       [0.20825516],\n",
       "       [0.41275797],\n",
       "       [0.22514071],\n",
       "       [0.38273921],\n",
       "       [0.32082552],\n",
       "       [0.15478424],\n",
       "       [0.2260788 ],\n",
       "       [0.29831144],\n",
       "       [0.18761726],\n",
       "       [0.29362101],\n",
       "       [0.37992495],\n",
       "       [0.23076923],\n",
       "       [0.12945591],\n",
       "       [0.23452158],\n",
       "       [0.21763602],\n",
       "       [0.21294559],\n",
       "       [0.29643527],\n",
       "       [0.45778612],\n",
       "       [0.25891182],\n",
       "       [0.13227017],\n",
       "       [0.21482176],\n",
       "       [0.26547842],\n",
       "       [0.2054409 ],\n",
       "       [0.33302064],\n",
       "       [0.3902439 ],\n",
       "       [0.23827392],\n",
       "       [0.15196998],\n",
       "       [0.23639775],\n",
       "       [0.22795497],\n",
       "       [0.23545966],\n",
       "       [0.23827392],\n",
       "       [0.43902439],\n",
       "       [0.26547842],\n",
       "       [0.1369606 ],\n",
       "       [0.17260788],\n",
       "       [0.2326454 ],\n",
       "       [0.24390244],\n",
       "       [0.22983114],\n",
       "       [0.40150094],\n",
       "       [0.25609756],\n",
       "       [0.17260788],\n",
       "       [0.20731707],\n",
       "       [0.21763602],\n",
       "       [0.17917448],\n",
       "       [0.26923077],\n",
       "       [0.34803002],\n",
       "       [0.28611632],\n",
       "       [0.15103189],\n",
       "       [0.19418386],\n",
       "       [0.23639775],\n",
       "       [0.2120075 ],\n",
       "       [0.18574109],\n",
       "       [0.44465291],\n",
       "       [0.28236398],\n",
       "       [0.2195122 ],\n",
       "       [0.23921201],\n",
       "       [0.2467167 ],\n",
       "       [0.2532833 ],\n",
       "       [0.24902638],\n",
       "       [0.41181989],\n",
       "       [0.25797373],\n",
       "       [0.19699812],\n",
       "       [0.22514071],\n",
       "       [0.2195122 ],\n",
       "       [0.28893058],\n",
       "       [0.29924953],\n",
       "       [0.44090056],\n",
       "       [0.37992495],\n",
       "       [0.22514071],\n",
       "       [0.18198874],\n",
       "       [0.26266417],\n",
       "       [0.21857411],\n",
       "       [0.31425891],\n",
       "       [0.31238274],\n",
       "       [0.28142589],\n",
       "       [0.63133208],\n",
       "       [0.29080675],\n",
       "       [0.25703565],\n",
       "       [0.36679174],\n",
       "       [0.42120075],\n",
       "       [0.48592871],\n",
       "       [0.38649156],\n",
       "       [0.22514071],\n",
       "       [0.25140713],\n",
       "       [0.23358349],\n",
       "       [0.28142589],\n",
       "       [0.21575985],\n",
       "       [0.48592871],\n",
       "       [0.41181989],\n",
       "       [0.15478424],\n",
       "       [0.13320826],\n",
       "       [0.2195122 ],\n",
       "       [0.20450281],\n",
       "       [0.33771107],\n",
       "       [0.52814259],\n",
       "       [0.30018762],\n",
       "       [0.20168856],\n",
       "       [0.16979362],\n",
       "       [0.22795497],\n",
       "       [0.2467167 ],\n",
       "       [0.34896811],\n",
       "       [0.48030019],\n",
       "       [0.35834897],\n",
       "       [0.1782364 ],\n",
       "       [0.2195122 ],\n",
       "       [0.184803  ],\n",
       "       [0.14821764],\n",
       "       [0.33771107],\n",
       "       [0.62007505],\n",
       "       [0.2673546 ],\n",
       "       [0.14540338],\n",
       "       [0.22138837],\n",
       "       [0.22514071],\n",
       "       [0.15009381],\n",
       "       [0.3011257 ],\n",
       "       [0.61350844],\n",
       "       [0.35928705],\n",
       "       [0.11257036],\n",
       "       [0.13977486],\n",
       "       [0.25422139],\n",
       "       [0.16228893],\n",
       "       [0.23639775],\n",
       "       [0.63414634],\n",
       "       [0.42589118],\n",
       "       [0.15384615],\n",
       "       [0.12195122],\n",
       "       [0.20825516],\n",
       "       [0.19981238],\n",
       "       [0.26454034],\n",
       "       [0.56097561],\n",
       "       [0.42870544],\n",
       "       [0.15947467],\n",
       "       [0.13133208],\n",
       "       [0.12945591],\n",
       "       [0.16041276],\n",
       "       [0.26923077],\n",
       "       [0.68292683],\n",
       "       [0.3424015 ],\n",
       "       [0.09662289],\n",
       "       [0.17729831],\n",
       "       [0.2054409 ],\n",
       "       [0.22889306],\n",
       "       [0.26547842],\n",
       "       [0.7467167 ],\n",
       "       [0.43621013],\n",
       "       [0.13320826],\n",
       "       [0.1782364 ],\n",
       "       [0.17917448],\n",
       "       [0.28893058],\n",
       "       [0.29174484],\n",
       "       [0.47185741],\n",
       "       [0.48217636],\n",
       "       [0.43433396],\n",
       "       [0.34896811],\n",
       "       [0.09756098],\n",
       "       [0.1575985 ],\n",
       "       [0.23827392],\n",
       "       [0.5478424 ],\n",
       "       [0.29831144],\n",
       "       [0.08348968],\n",
       "       [0.16604128],\n",
       "       [0.21763602],\n",
       "       [0.17542214],\n",
       "       [0.28330206],\n",
       "       [0.65384615],\n",
       "       [0.2945591 ],\n",
       "       [0.07223265],\n",
       "       [0.15666041],\n",
       "       [0.19230769],\n",
       "       [0.17729831],\n",
       "       [0.33020638],\n",
       "       [0.54409006],\n",
       "       [0.39868668],\n",
       "       [0.12382739],\n",
       "       [0.19418386],\n",
       "       [0.18574109],\n",
       "       [0.18574109],\n",
       "       [0.24202627],\n",
       "       [0.57692308],\n",
       "       [0.35459662],\n",
       "       [0.10225141],\n",
       "       [0.16135084],\n",
       "       [0.12195122]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize data with MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y[\"Ospiti\"].values.reshape(-1,1))\n",
    "y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data windowing with a 30 days window\n",
    "window_size = 30\n",
    "window = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    data=y[\"Ospiti\"],\n",
    "    targets=None,\n",
    "    sequence_length=window_size,\n",
    "    sequence_stride=1,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a forecasting model using the Keras Sequential API\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(256, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(128, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(64, activation=\"relu\", name=\"layer3\"),\n",
    "        layers.Dense(7, name=\"layer4\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/davide/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/davide/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/davide/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/davide/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/davide/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/davide/.local/lib/python3.8/site-packages/keras/layers/core/dense.py\", line 139, in build\n        raise ValueError('The last dimension of the inputs to a Dense layer '\n\n    ValueError: Exception encountered when calling layer \"sequential_3\" (type Sequential).\n    \n    The last dimension of the inputs to a Dense layer should be defined. Found None. Full input shape received: (None, None)\n    \n    Call arguments received:\n      â€¢ inputs=tf.Tensor(shape=(None, None), dtype=float64)\n      â€¢ training=True\n      â€¢ mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4181/2136585847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/davide/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/davide/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/davide/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/davide/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/davide/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/davide/.local/lib/python3.8/site-packages/keras/layers/core/dense.py\", line 139, in build\n        raise ValueError('The last dimension of the inputs to a Dense layer '\n\n    ValueError: Exception encountered when calling layer \"sequential_3\" (type Sequential).\n    \n    The last dimension of the inputs to a Dense layer should be defined. Found None. Full input shape received: (None, None)\n    \n    Call arguments received:\n      â€¢ inputs=tf.Tensor(shape=(None, None), dtype=float64)\n      â€¢ training=True\n      â€¢ mask=None\n"
     ]
    }
   ],
   "source": [
    "model.fit(window,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
